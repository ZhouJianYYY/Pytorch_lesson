{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm 范数 \n",
    "# sum max min prod \n",
    "# argmin argmax \n",
    "# topk\n",
    "# where gather "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) tensor([3., 3., 3., 3., 3.])\n",
      "torch.Size([3])\n",
      "torch.Size([5])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "a =torch.randn(3,5)\n",
    "a =torch.ones(3,5)\n",
    "print(a.norm(1,dim=0).shape,a.norm(1,dim=0))\n",
    "print(a.norm(1,dim=1).shape)\n",
    "print(a.norm(2,dim=0).shape)\n",
    "print(a.norm(1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sum max min prod "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.5046) tensor(-0.8565) tensor(-7.2106e-06)\n",
      "tensor([[ 0.2038,  0.1896, -0.8313,  1.9990, -0.6776],\n",
      "        [ 0.3438, -0.0460,  0.1355,  0.8630,  0.3408],\n",
      "        [ 0.4204, -0.4637,  0.4597, -0.8565,  3.4240]])\n"
     ]
    }
   ],
   "source": [
    "a =torch.randn(3,5)\n",
    "print(a.sum(),a.min(),a.prod()) # prod 累计值 也可以指定dim\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# argmax argmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9817, -0.8484,  0.2975, -1.1879, -0.0998],\n",
      "        [ 1.3036, -0.9048,  0.8158,  1.2423,  0.9522],\n",
      "        [-0.5522,  0.0352, -0.1532, -0.3450, -0.7925]])\n",
      "tensor(5)\n",
      "tensor(3)\n",
      "tensor([1, 2, 1, 1, 1])\n",
      "tensor([0, 1, 2, 0, 2])\n",
      "tensor([3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "a =torch.randn(3,5)\n",
    "print(a)\n",
    "print(a.argmax()) # 打平之后的位置索引\n",
    "print(a.argmin())# 打平之后的位置索引\n",
    "print(a.argmax(dim=0))\n",
    "print(a.argmin(dim=0))\n",
    "print(a.argmin(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 0, 2]])\n",
      "torch.return_types.min(\n",
      "values=tensor([[-0.9817, -0.9048, -0.1532, -1.1879, -0.7925]]),\n",
      "indices=tensor([[0, 1, 2, 0, 2]]))\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "# 使用keepdim=True可以保持应有的dim，即仅仅是将求最值的那个dim的size变成了1\n",
    "print(a.argmin(dim=0,keepdim=True))\n",
    "print(a.min(dim=0,keepdim=True))\n",
    "print(a.argmin(dim=0,keepdim=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# topk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9817, -0.8484,  0.2975, -1.1879, -0.0998],\n",
      "        [ 1.3036, -0.9048,  0.8158,  1.2423,  0.9522],\n",
      "        [-0.5522,  0.0352, -0.1532, -0.3450, -0.7925]])\n",
      "tensor([[2, 4],\n",
      "        [0, 3],\n",
      "        [1, 2]])\n",
      "tensor([[3],\n",
      "        [1],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "# 求最小的k个，只要使用参数largest=False。\n",
    "print(a)\n",
    "print(a.topk(2,dim=1)[1])\n",
    "print(a.topk(1,dim=1,largest=False)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# where "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "tensor([[4, 5],\n",
      "        [6, 7]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[4, 1],\n",
       "        [6, 3]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond = torch.tensor([[0.3,0.7],[0.1,0.9]])\n",
    "a = torch.arange(0,4).reshape(2,2)\n",
    "print(a)\n",
    "b = torch.arange(4,8).reshape(2,2)\n",
    "print(b)\n",
    "torch.where(cond>0.5,a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 7, 4],\n",
      "        [8, 0, 4],\n",
      "        [2, 9, 7],\n",
      "        [3, 8, 7]])\n",
      "tensor([100, 101, 102, 103, 104, 105, 106, 107, 108, 109])\n",
      "tensor([[103, 107, 104],\n",
      "        [108, 100, 104],\n",
      "        [102, 109, 107],\n",
      "        [103, 108, 107]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
       "        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
       "        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
       "        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather(input, dim, index, out=None, sparse_grad=False) -> Tensor\n",
    "# 使用torch.gather(input,dim,index)对元素实现一个查表映射的操作\n",
    "prob = torch.randn(4, 10)\n",
    "_, idx = prob.topk(3, dim=1)\n",
    "print(idx)\n",
    "ipt = torch.arange(10) + 100\n",
    "print(ipt)  # 用于将idx的0~9映射到100~109\n",
    "out = torch.gather(ipt.expand(4, 10), dim=1, index=idx.long())\n",
    "print(out)\n",
    "ipt.expand(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
