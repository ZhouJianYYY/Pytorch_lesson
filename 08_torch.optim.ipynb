{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.optim.Optimizer(params, defaults)**  \n",
    "def load_state_dict   \n",
    "def state_dict()    \n",
    "def step(closure)    \n",
    "def zero_grad(set_to_none: bool = False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adadelta\n",
    "**Adadelta(params, lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adagrad\n",
    "**Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam\n",
    "**Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdamW\n",
    "**AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparseAdam\n",
    "**SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax\n",
    "**Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASGD\n",
    "**ASGD(params, lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBFGS\n",
    "**LBFGS(params, lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=None)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop\n",
    "**RMSprop(params, lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rprop\n",
    "**Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-06, 50))**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "**SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjust learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.LambdaLR \n",
    "**lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lambda1 = lambda epoch: epoch // 30\n",
    "    lambda2 = lambda epoch: 0.95 ** epoch\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=[lambda1, lambda2])\n",
    "    for epoch in range(100):\n",
    "        train(...)\n",
    "        validate(...)\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.MultiplicativeLR\n",
    "**lr_scheduler.MultiplicativeLR(optimizer, lr_lambda, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.StepLR\n",
    "**lr_scheduler.StepLR(optimizer, step_size, gamma=0.1, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    >>> # Assuming optimizer uses lr = 0.05 for all groups\n",
    "    >>> # lr = 0.05     if epoch < 30\n",
    "    >>> # lr = 0.005    if 30 <= epoch < 60\n",
    "    >>> # lr = 0.0005   if 60 <= epoch < 90\n",
    "    >>> # ...\n",
    "    >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    >>> for epoch in range(100):\n",
    "    >>>     train(...)\n",
    "    >>>     validate(...)\n",
    "    >>>     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.MultiStepLR\n",
    "**lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        >>> # Assuming optimizer uses lr = 0.05 for all groups\n",
    "        >>> # lr = 0.05     if epoch < 30\n",
    "        >>> # lr = 0.005    if 30 <= epoch < 80\n",
    "        >>> # lr = 0.0005   if epoch >= 80\n",
    "        >>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
    "        >>> for epoch in range(100):\n",
    "        >>>     train(...)\n",
    "        >>>     validate(...)\n",
    "        >>>     scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.CosineAnnealingLR\n",
    "**lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.ReduceLROnPlateau\n",
    "**lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.CyclicLR\n",
    "**lr_scheduler.CyclicLR(optimizer, base_lr, max_lr, step_size_up=2000, step_size_down=None, mode='triangular', gamma=1.0, scale_fn=None, scale_mode='cycle', cycle_momentum=True, base_momentum=0.8, max_momentum=0.9, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.OneCycleLR\n",
    "**lr_scheduler.OneCycleLR(optimizer, max_lr, total_steps=None, epochs=None, steps_per_epoch=None, pct_start=0.3, anneal_strategy='cos', cycle_momentum=True, base_momentum=0.85, max_momentum=0.95, div_factor=25.0, final_div_factor=10000.0, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lr_scheduler.CosineAnnealingWarmRestarts\n",
    "**lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0, T_mult=1, eta_min=0, last_epoch=-1, verbose=False)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "240.17px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
