{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch使您可以自由地对Dataset类执行任何操作，只要您重写改类中的两个函数即可：\n",
    "\n",
    "* \\_\\_len__ 函数：返回数据集大小\n",
    "* \\_\\_getitem__ 函数：返回对应索引的数据集中的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberDateset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(NumberDateset,self).__init__()\n",
    "        self.data = list(range(0,100))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "10\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset= NumberDateset()\n",
    "    print(len(dataset))\n",
    "    print(dataset[10])\n",
    "    print(dataset[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberDateset(Dataset):\n",
    "    def __init__(self,low,high):\n",
    "        super(NumberDateset,self).__init__()\n",
    "        self.data = list(range(low,high))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "20\n",
      "[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset= NumberDateset(10,321)\n",
    "    print(len(dataset))\n",
    "    print(dataset[10])\n",
    "    print(dataset[20:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "class TESNamesDataset(Dataset):\n",
    "    def __init__(self,data_root):\n",
    "        self.sample= []\n",
    "        for race in os.listdir(data_root):\n",
    "            race_folder = os.path.join(data_root,race)\n",
    "            for gender in os.listdir(race_folder):\n",
    "                gender_filepath = os.path.join(race_folder,gender)\n",
    "                with open(gender_filepath,'r') as f:\n",
    "                    for name in f.read().splitlines():\n",
    "                        self.sample.append((race,gender,name))\n",
    "#                     self.sample.extend(f.read().split())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.sample[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19491\n",
      "('Altmer', 'Female', 'Hanyarie')\n",
      "[('Altmer', 'Female', 'Alanwe'), ('Altmer', 'Female', 'Alanya'), ('Altmer', 'Female', 'Alcalime'), ('Altmer', 'Female', 'Alcardawe'), ('Altmer', 'Female', 'Alcildilwe'), ('Altmer', 'Female', 'Alcorana'), ('Altmer', 'Female', 'Aldamaire'), ('Altmer', 'Female', 'Aldanya'), ('Altmer', 'Female', 'Aldarenya'), ('Altmer', 'Female', 'Aldewe'), ('Altmer', 'Female', 'Aldimonwe'), ('Altmer', 'Female', 'Aldononde'), ('Altmer', 'Female', 'Aldunie'), ('Altmer', 'Female', 'Alduril'), ('Altmer', 'Female', 'Aldurlde'), ('Altmer', 'Female', 'Alerume'), ('Altmer', 'Female', 'Alinisse'), ('Altmer', 'Female', 'Alirfire'), ('Altmer', 'Female', 'Alisewen'), ('Altmer', 'Female', 'Alque'), ('Altmer', 'Female', 'Alquufwe'), ('Altmer', 'Female', 'Altansawen'), ('Altmer', 'Female', 'Altininde'), ('Altmer', 'Female', 'Altoririe'), ('Altmer', 'Female', 'Alwaen'), ('Altmer', 'Female', 'Alwe'), ('Altmer', 'Female', 'Alwinarwe'), ('Altmer', 'Female', 'Amaleera'), ('Altmer', 'Female', 'Ambarel'), ('Altmer', 'Female', 'Ambaril'), ('Altmer', 'Female', 'Aminore'), ('Altmer', 'Female', 'Amirmil'), ('Altmer', 'Female', 'Analande'), ('Altmer', 'Female', 'Anaril'), ('Altmer', 'Female', 'Ancalin'), ('Altmer', 'Female', 'Anconath'), ('Altmer', 'Female', 'Andalore'), ('Altmer', 'Female', 'Andenyerinwe'), ('Altmer', 'Female', 'Andewen'), ('Altmer', 'Female', 'Andiryewen'), ('Altmer', 'Female', 'Andorie'), ('Altmer', 'Female', 'Andraginia'), ('Altmer', 'Female', 'Andralia'), ('Altmer', 'Female', 'Andralina'), ('Altmer', 'Female', 'Andramia'), ('Altmer', 'Female', 'Andrana'), ('Altmer', 'Female', 'Andrasara'), ('Altmer', 'Female', 'Andrasephona'), ('Altmer', 'Female', 'Andrasha'), ('Altmer', 'Female', 'Andratha')]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data_root = \"./data/tes-names/\"\n",
    "    dataset= TESNamesDataset(data_root)\n",
    "    print(len(dataset))\n",
    "    print(dataset[420])\n",
    "    print(dataset[10:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"./data/tes-names/Altmer/Female\",'r') as f :\n",
    "#     sample = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Dunmer', 'Breton', 'Dunmer', 'Redguard', 'Breton', 'Altmer', 'Orc', 'Altmer', 'Dunmer', 'Imperial'), ('Male', 'Male', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Male'), ('Delmon', 'Perastyr', 'Angarthal', 'Burhan', 'Amelus', 'Ohtaari', 'Morbash', 'Cimalire', 'Munbi', 'Calvus')]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    from torch.utils.data import DataLoader\n",
    "    dataset= TESNamesDataset(\"./data/tes-names/\")\n",
    "    datasetloader = DataLoader(dataset,shuffle=True,batch_size=10)\n",
    "    batch = next(iter(datasetloader))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量垂直堆叠（即在第一维上）构成batch。此外，DataLoader还会为对数据进行重新排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class NumberDateset(Dataset):\n",
    "    def __init__(self,low,high):\n",
    "        self.sample = list(range(low,high))\n",
    "    def __len__(self):\n",
    "        return len(self.sample)\n",
    "    def __getitem__(self,idx):\n",
    "        n = self.sample[idx]\n",
    "        successors = torch.arange(4).float() +n+1\n",
    "        noisy = torch.randn(4) + successors\n",
    "        return n,successors,noisy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n",
      "(20, tensor([21., 22., 23., 24.]), tensor([21.9005, 21.9934, 21.3350, 24.3451]))\n",
      "[tensor([138, 104, 152, 290, 296,  52, 315,  36,  92, 194]), tensor([[139., 140., 141., 142.],\n",
      "        [105., 106., 107., 108.],\n",
      "        [153., 154., 155., 156.],\n",
      "        [291., 292., 293., 294.],\n",
      "        [297., 298., 299., 300.],\n",
      "        [ 53.,  54.,  55.,  56.],\n",
      "        [316., 317., 318., 319.],\n",
      "        [ 37.,  38.,  39.,  40.],\n",
      "        [ 93.,  94.,  95.,  96.],\n",
      "        [195., 196., 197., 198.]]), tensor([[140.0013, 141.4332, 140.3532, 142.1546],\n",
      "        [105.8110, 106.2807, 106.9251, 109.2045],\n",
      "        [151.2348, 154.2180, 155.4088, 157.1062],\n",
      "        [289.5518, 293.0112, 294.4333, 293.7364],\n",
      "        [295.8699, 298.9415, 298.9690, 300.6281],\n",
      "        [ 52.0438,  52.5129,  54.5421,  55.1710],\n",
      "        [315.9795, 316.5418, 316.4810, 320.9484],\n",
      "        [ 36.2474,  40.7714,  38.4575,  39.7063],\n",
      "        [ 94.2519,  95.2219,  95.3093,  94.3174],\n",
      "        [193.0816, 196.4731, 196.5541, 198.3528]])]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset= NumberDateset(10,321)\n",
    "    print(len(dataset))\n",
    "    print(dataset[10])\n",
    "    datasetloader = DataLoader(dataset,batch_size=10,shuffle=True)\n",
    "    print(next(iter(datasetloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为清理TES数据集的代码，我们将更新TESNamesDataset的代码来实现以下目的：\n",
    "\n",
    "* 更新构造函数以包含字符集   \n",
    "* 创建一个内部函数来初始化数据集   \n",
    "* 创建一个将标量转换为独热(one-hot)张量的工具函数  \n",
    "* 创建一个工具函数，该函数将样本数据转换为种族，性别和名称的三个独热(one-hot)张量的集合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TESNamesDateset(Dataset):\n",
    "    def __init__(self,data_root,charset,length):\n",
    "        self.data_root = data_root\n",
    "        self.charset = charset + '\\0'\n",
    "        self.length = length\n",
    "        self.sample =[]\n",
    "        self.race_codec = LabelEncoder()\n",
    "        self.gender_codec = LabelEncoder()\n",
    "        self.char_codec = LabelEncoder()\n",
    "        self._init_dataset()\n",
    "    def __len__(self):\n",
    "        return len(self.sample)\n",
    "    def __getitem__(self,idx):\n",
    "        race,gender,name = self.sample[idx]\n",
    "        return self.one_hot_sample(race,gender,name)\n",
    "    def _init_dataset(self):\n",
    "        races = set()\n",
    "        genders =set()\n",
    "        for race in os.listdir(self.data_root):\n",
    "            race_folder = os.path.join(self.data_root,race)\n",
    "            races.add(race)\n",
    "            for gender in os.listdir(race_folder):\n",
    "                gender_filepath = os.path.join(race_folder,gender)\n",
    "                genders.add(gender)\n",
    "                with open(gender_filepath,'r') as f:\n",
    "                    for name in f.read().splitlines():\n",
    "                        if len(name)< self.length:\n",
    "                            name +=\"\\0\"*(self.length-len(name))\n",
    "                        else:\n",
    "                            name = name[:self.length-1] + '\\0'\n",
    "                        self.sample.append((race,gender,name))\n",
    "        self.race_codec.fit(list(races))\n",
    "        self.gender_codec.fit(list(genders))        \n",
    "        self.char_codec.fit(list(self.charset))\n",
    "        \n",
    "    def to_one_hot(self,codec,values):\n",
    "        values_idxs = codec.transform(values)\n",
    "        return torch.eye(len(codec.classes_))[values_idxs]\n",
    "    \n",
    "    def one_hot_sample(self,race,gender,name):\n",
    "        t_race = self.to_one_hot(self.race_codec,[race])\n",
    "        t_gender = self.to_one_hot(self.gender_codec,[gender])\n",
    "        t_name = self.to_one_hot(self.char_codec,list(name))\n",
    "        return t_race,t_gender,t_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19491\n",
      "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), tensor([[1., 0.]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]]))\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    import string\n",
    "    data_root = './data/tes-names/'\n",
    "    charset = string.ascii_letters + \"-' \"\n",
    "    dataset = TESNamesDateset(data_root,charset,10)\n",
    "    print(len(dataset))\n",
    "    print(dataset[420])\n",
    "    dataloader = DataLoader(dataset,batch_size=10)\n",
    "    batch= next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 56])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 55])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_one_hot(dataset.char_codec,list('Hanyarie')).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
