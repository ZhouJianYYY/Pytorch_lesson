{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid tanh relu  softmax\n",
    "# torch.nn.functional下，可以直接使用  mse_loss cross_entorpy_loss\n",
    "# torch.autograd.grad  loss .backward "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sigmoid tanh relu  softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-10.0000,  -9.6000,  -9.2000,  -8.8000,  -8.4000,  -8.0000,  -7.6000,\n",
      "         -7.2000,  -6.8000,  -6.4000,  -6.0000,  -5.6000,  -5.2000,  -4.8000,\n",
      "         -4.4000,  -4.0000,  -3.6000,  -3.2000,  -2.8000,  -2.4000,  -2.0000,\n",
      "         -1.6000,  -1.2000,  -0.8000,  -0.4000,   0.0000,   0.4000,   0.8000,\n",
      "          1.2000,   1.6000,   2.0000,   2.4000,   2.8000,   3.2000,   3.6000,\n",
      "          4.0000,   4.4000,   4.8000,   5.2000,   5.6000,   6.0000,   6.4000,\n",
      "          6.8000,   7.2000,   7.6000,   8.0000,   8.4000,   8.8000,   9.2000,\n",
      "          9.6000,  10.0000])\n",
      "tensor([4.5398e-05, 6.7724e-05, 1.0103e-04, 1.5071e-04, 2.2482e-04, 3.3535e-04,\n",
      "        5.0020e-04, 7.4603e-04, 1.1125e-03, 1.6588e-03, 2.4726e-03, 3.6842e-03,\n",
      "        5.4863e-03, 8.1626e-03, 1.2128e-02, 1.7986e-02, 2.6597e-02, 3.9166e-02,\n",
      "        5.7324e-02, 8.3173e-02, 1.1920e-01, 1.6798e-01, 2.3148e-01, 3.1003e-01,\n",
      "        4.0131e-01, 5.0000e-01, 5.9869e-01, 6.8997e-01, 7.6852e-01, 8.3202e-01,\n",
      "        8.8080e-01, 9.1683e-01, 9.4268e-01, 9.6083e-01, 9.7340e-01, 9.8201e-01,\n",
      "        9.8787e-01, 9.9184e-01, 9.9451e-01, 9.9632e-01, 9.9753e-01, 9.9834e-01,\n",
      "        9.9889e-01, 9.9925e-01, 9.9950e-01, 9.9966e-01, 9.9978e-01, 9.9985e-01,\n",
      "        9.9990e-01, 9.9993e-01, 9.9995e-01])\n"
     ]
    }
   ],
   "source": [
    "a = torch.linspace(-10,10,51)\n",
    "print(a)\n",
    "print(torch.sigmoid(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
      "        -1.0000, -1.0000, -1.0000, -1.0000, -0.9999, -0.9999, -0.9997, -0.9993,\n",
      "        -0.9985, -0.9967, -0.9926, -0.9837, -0.9640, -0.9217, -0.8337, -0.6640,\n",
      "        -0.3799,  0.0000,  0.3799,  0.6640,  0.8337,  0.9217,  0.9640,  0.9837,\n",
      "         0.9926,  0.9967,  0.9985,  0.9993,  0.9997,  0.9999,  0.9999,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000,  1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tanh(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.4000,  0.8000,  1.2000,  1.6000,  2.0000,  2.4000,\n",
      "         2.8000,  3.2000,  3.6000,  4.0000,  4.4000,  4.8000,  5.2000,  5.6000,\n",
      "         6.0000,  6.4000,  6.8000,  7.2000,  7.6000,  8.0000,  8.4000,  8.8000,\n",
      "         9.2000,  9.6000, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.relu(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.7952e-10, 1.0137e-09, 1.5123e-09, 2.2561e-09, 3.3657e-09, 5.0210e-09,\n",
      "        7.4905e-09, 1.1174e-08, 1.6670e-08, 2.4869e-08, 3.7101e-08, 5.5348e-08,\n",
      "        8.2569e-08, 1.2318e-07, 1.8376e-07, 2.7414e-07, 4.0897e-07, 6.1011e-07,\n",
      "        9.1017e-07, 1.3578e-06, 2.0256e-06, 3.0219e-06, 4.5081e-06, 6.7253e-06,\n",
      "        1.0033e-05, 1.4967e-05, 2.2329e-05, 3.3311e-05, 4.9694e-05, 7.4134e-05,\n",
      "        1.1060e-04, 1.6499e-04, 2.4613e-04, 3.6719e-04, 5.4778e-04, 8.1719e-04,\n",
      "        1.2191e-03, 1.8187e-03, 2.7132e-03, 4.0476e-03, 6.0383e-03, 9.0081e-03,\n",
      "        1.3438e-02, 2.0048e-02, 2.9908e-02, 4.4617e-02, 6.6561e-02, 9.9298e-02,\n",
      "        1.4813e-01, 2.2099e-01, 3.2968e-01])\n"
     ]
    }
   ],
   "source": [
    "print(F.softmax(a,dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.7952e-10, 1.0137e-09, 1.5123e-09, 2.2561e-09, 3.3657e-09, 5.0210e-09,\n",
      "        7.4905e-09, 1.1174e-08, 1.6670e-08, 2.4869e-08, 3.7101e-08, 5.5348e-08,\n",
      "        8.2569e-08, 1.2318e-07, 1.8376e-07, 2.7414e-07, 4.0897e-07, 6.1011e-07,\n",
      "        9.1017e-07, 1.3578e-06, 2.0256e-06, 3.0219e-06, 4.5081e-06, 6.7253e-06,\n",
      "        1.0033e-05, 1.4967e-05, 2.2329e-05, 3.3311e-05, 4.9694e-05, 7.4134e-05,\n",
      "        1.1060e-04, 1.6499e-04, 2.4613e-04, 3.6719e-04, 5.4778e-04, 8.1719e-04,\n",
      "        1.2191e-03, 1.8187e-03, 2.7132e-03, 4.0476e-03, 6.0383e-03, 9.0081e-03,\n",
      "        1.3438e-02, 2.0048e-02, 2.9908e-02, 4.4617e-02, 6.6561e-02, 9.9298e-02,\n",
      "        1.4813e-01, 2.2099e-01, 3.2968e-01])\n"
     ]
    }
   ],
   "source": [
    "print(torch.softmax(a,dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mse_loss cross_entorpy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5301, 0.4399, 0.8713, 0.9451])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.1385)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(4)\n",
    "print(a)\n",
    "loss = F.mse_loss(torch.full([4],1),a)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# input, NxC=2x3\n",
    "\n",
    "input = torch.randn(2, 3, requires_grad=True)\n",
    "\n",
    "# target, N\n",
    "\n",
    "target = torch.empty(2, dtype=torch.long).random_(3)\n",
    "output = loss(input, target)\n",
    "output.backward()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch.autograd.grad  loss .backward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1])\n",
      "tensor(4.6470)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(4,5)\n",
    "w = torch.rand(1,5)\n",
    "y = torch.ones(4)\n",
    "pred = a@w.t()\n",
    "print(pred.shape)\n",
    "loss = F.mse_loss(y,pred)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dcfcd61cfb42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 没有设定其需要梯度信息，所以PyTorch在建图的时候就没有设置它具有梯度信息。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[0;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         inputs, allow_unused)\n\u001b[0m\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "res = torch.autograd.grad(loss,[w])\n",
    "# 没有设定其需要梯度信息，所以PyTorch在建图的时候就没有设置它具有梯度信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x65751b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740]], requires_grad=True)\n",
      "tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "(tensor([[1.6537, 1.6537, 1.6537, 1.6537, 1.6537]]),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# method_1\n",
    "torch.manual_seed(123)\n",
    "w = torch.rand(1,5)\n",
    "w.requires_grad_()\n",
    "print(w)\n",
    "pred = a@w.t()\n",
    "loss = F.mse_loss(y,pred)\n",
    "print(loss)\n",
    "res = torch.autograd.grad(loss,[w])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740]], requires_grad=True)\n",
      "tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "(tensor([[1.6537, 1.6537, 1.6537, 1.6537, 1.6537]]),)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# method_2\n",
    "torch.manual_seed(123)\n",
    "w = torch.rand(1,5,requires_grad=True)\n",
    "print(w)\n",
    "pred = a@w.t()\n",
    "loss = F.mse_loss(y,pred)\n",
    "print(loss)\n",
    "res = torch.autograd.grad(loss,[w])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740]], requires_grad=True)\n",
      "tensor(0.6837, grad_fn=<MeanBackward0>)\n",
      "tensor([[1.6537, 1.6537, 1.6537, 1.6537, 1.6537]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\software\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Using a target size (torch.Size([4, 1])) that is different to the input size (torch.Size([4])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# method_3\n",
    "torch.manual_seed(123)\n",
    "w = torch.rand(1,5,requires_grad=True)\n",
    "print(w)\n",
    "pred = a@w.t()\n",
    "loss = F.mse_loss(y,pred)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(w.grad)#  method_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.2708)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,784)\n",
    "w = torch.randn(10,784)\n",
    "logit = x@w.t()\n",
    "loss = F.cross_entropy(logit,torch.tensor([3]))\n",
    "print(loss)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
