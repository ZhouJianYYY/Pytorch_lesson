{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "from visdom import Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\n",
    "    root='./data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.module = nn.Sequential(nn.Linear(784, 256), nn.ReLU(inplace=True),\n",
    "                                    nn.Linear(256, 64), nn.ReLU(inplace=True),\n",
    "                                    nn.Linear(64, 10), nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 2.2973036766052246\n",
      "0 100 loss: 2.2841978073120117\n",
      "0 200 loss: 2.262608051300049\n",
      "0 300 loss: 2.2666118144989014\n",
      "0 400 loss: 2.255567789077759\n",
      "0 acc : 39.39\n",
      "1 0 loss: 2.2496254444122314\n",
      "1 100 loss: 2.2269506454467773\n",
      "1 200 loss: 2.1947216987609863\n",
      "1 300 loss: 2.150509834289551\n",
      "1 400 loss: 2.1462271213531494\n",
      "1 acc : 55.60\n",
      "2 0 loss: 2.1200404167175293\n",
      "2 100 loss: 2.0836169719696045\n",
      "2 200 loss: 2.070380926132202\n",
      "2 300 loss: 2.0236196517944336\n",
      "2 400 loss: 1.9937987327575684\n",
      "2 acc : 58.44\n",
      "3 0 loss: 1.9546140432357788\n",
      "3 100 loss: 1.8760817050933838\n",
      "3 200 loss: 1.8718754053115845\n",
      "3 300 loss: 1.709803581237793\n",
      "3 400 loss: 1.7052797079086304\n",
      "3 acc : 67.26\n",
      "4 0 loss: 1.7146868705749512\n",
      "4 100 loss: 1.5388858318328857\n",
      "4 200 loss: 1.5955249071121216\n",
      "4 300 loss: 1.5448435544967651\n",
      "4 400 loss: 1.4483821392059326\n",
      "4 acc : 71.18\n",
      "5 0 loss: 1.4001269340515137\n",
      "5 100 loss: 1.128952980041504\n",
      "5 200 loss: 1.189605474472046\n",
      "5 300 loss: 1.1683175563812256\n",
      "5 400 loss: 0.9862909913063049\n",
      "5 acc : 74.70\n",
      "6 0 loss: 1.0696474313735962\n",
      "6 100 loss: 1.1034183502197266\n",
      "6 200 loss: 0.9446343779563904\n",
      "6 300 loss: 1.0771123170852661\n",
      "6 400 loss: 0.9672524333000183\n",
      "6 acc : 76.97\n",
      "7 0 loss: 0.9951770901679993\n",
      "7 100 loss: 1.0784655809402466\n",
      "7 200 loss: 0.8616252541542053\n",
      "7 300 loss: 0.8449938893318176\n",
      "7 400 loss: 0.8062404990196228\n",
      "7 acc : 78.36\n",
      "8 0 loss: 0.9053820967674255\n",
      "8 100 loss: 0.8253247141838074\n",
      "8 200 loss: 0.7693036198616028\n",
      "8 300 loss: 0.8418588638305664\n",
      "8 400 loss: 0.8173951506614685\n",
      "8 acc : 78.83\n",
      "9 0 loss: 0.8098062872886658\n",
      "9 100 loss: 0.8659058213233948\n",
      "9 200 loss: 0.7236654758453369\n",
      "9 300 loss: 0.7218294739723206\n",
      "9 400 loss: 0.8594711422920227\n",
      "9 acc : 79.49\n",
      "10 0 loss: 0.7212582230567932\n",
      "10 100 loss: 0.7640708088874817\n",
      "10 200 loss: 0.7163949608802795\n",
      "10 300 loss: 0.8909304738044739\n",
      "10 400 loss: 0.7659041881561279\n",
      "10 acc : 80.01\n",
      "11 0 loss: 0.7254858613014221\n",
      "11 100 loss: 0.6796656847000122\n",
      "11 200 loss: 0.7443130016326904\n",
      "11 300 loss: 0.8376280069351196\n",
      "11 400 loss: 0.7948194146156311\n",
      "11 acc : 80.59\n",
      "12 0 loss: 0.758304238319397\n",
      "12 100 loss: 0.7270833253860474\n",
      "12 200 loss: 0.596520721912384\n",
      "12 300 loss: 0.6047815680503845\n",
      "12 400 loss: 0.5278005599975586\n",
      "12 acc : 80.93\n",
      "13 0 loss: 0.7169896364212036\n",
      "13 100 loss: 0.7863207459449768\n",
      "13 200 loss: 0.6000107526779175\n",
      "13 300 loss: 0.5522903203964233\n",
      "13 400 loss: 0.6581404209136963\n",
      "13 acc : 81.24\n",
      "14 0 loss: 0.8724410533905029\n",
      "14 100 loss: 0.6091601252555847\n",
      "14 200 loss: 0.7500534653663635\n",
      "14 300 loss: 0.5893217921257019\n",
      "14 400 loss: 0.6340204477310181\n",
      "14 acc : 81.45\n",
      "15 0 loss: 0.4929315447807312\n",
      "15 100 loss: 0.7293397784233093\n",
      "15 200 loss: 0.5542627573013306\n",
      "15 300 loss: 0.7438418865203857\n",
      "15 400 loss: 0.5801045298576355\n",
      "15 acc : 81.57\n",
      "16 0 loss: 0.47074568271636963\n",
      "16 100 loss: 0.6425483822822571\n",
      "16 200 loss: 0.5311844348907471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1b26d602bc0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mglobal_step\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\software\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# viz = Visdom()\n",
    "# viz.line([0.], [0.], win='train_loss', opts=dict(title='train loss'))\n",
    "# viz.line([[0.0, 0.0]], [0.],\n",
    "#          win='test',\n",
    "#          opts=dict(title='test loss&acc.', legend=['loss', 'acc.']))\n",
    "\n",
    "\n",
    "viz = Visdom()\n",
    "viz.line([0.],[0.0],win = 'train_loss', opts=dict(title='train_loss'))\n",
    "viz.line([0.],[0.0],win='test_acc', opts=dict(title='test_acc'))\n",
    "\n",
    "net = MLP()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
    "cel = nn.CrossEntropyLoss()\n",
    "global_step = 0\n",
    "for epoch in range(100):\n",
    "\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        x = x.reshape(-1, 784)\n",
    "        logit = net(x)\n",
    "        loss = cel(logit, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "        viz.line([loss.item()], [global_step],\n",
    "                 win='train_loss',\n",
    "                 update='append')\n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss:', loss.item())\n",
    "\n",
    "    correct = 0\n",
    "    total_cnt = 0\n",
    "    for data, target in test_loader:\n",
    "        # 摊平成shape=[样本数,784]的形状\n",
    "        data = data.reshape(-1, 28 * 28)\n",
    "        logits = net(data)\n",
    "#         test_loss = cel(logits, target)\n",
    "        #             test_loss += CEL(logits, target).item()\n",
    "        # 得到的预测值输出是一个10个分量的概率,在第2个维度上取max\n",
    "        # logits.data是一个shape=[batch_size,10]的Tensor\n",
    "        # 注意Tensor.max(dim=1)是在这个Tensor的1号维度上求最大值\n",
    "        # 得到一个含有两个元素的元组,这两个元素都是shape=[batch_size]的Tensor\n",
    "        # 第一个Tensor里面存的都是最大值的值,第二个Tensor里面存的是对应的索引\n",
    "        # 这里要取索引,所以取了这个tuple的第二个元素\n",
    "        #         print(type(logits.data), logits.data.shape,type(logits.data.max(dim=1)))\n",
    "        pred = torch.softmax(logits, dim=1)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        #         pred = logits.data.max(dim=1)[1]\n",
    "        # 对应位置相等则对应位置为True,这里用sum()即记录了True的数量\n",
    "        correct += torch.eq(pred, target).float().sum().item()\n",
    "        #             correct = pred.eq(y.data).sum()\n",
    "        #             correct_cnt+=correct\n",
    "        total_cnt += data.shape[0]\n",
    "    acc = correct / total_cnt * 100.0\n",
    "    viz.line([acc],[global_step], win='test_acc',update='append')\n",
    "    viz.images(data.view(-1,1,28,28), win='x')\n",
    "    viz.text(str(pred.detach().cpu().numpy()), win='pred')\n",
    "#     viz.line([[test_loss.item(), acc]], [global_step],\n",
    "#              win='test',\n",
    "#              update='append')\n",
    "    print(epoch, 'acc : {:.2f}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
