{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **三角函数**\n",
    "* torch.acos\n",
    "* torch.asin\n",
    "* torch.atan\n",
    "* torch.cos \n",
    "* torch.cosh 双曲余弦\n",
    "* torch.sin \n",
    "* torch.sinh 双曲正弦\n",
    "* torch.tan \n",
    "* torch.tanh 双曲正切"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **常用函数** \n",
    "* torch.add\n",
    "* torch.sub\n",
    "* torch.mul \n",
    "  torch.mul(input, value, out=None) 标量值value乘以input的每个元素\n",
    "* torch.div    \n",
    "   torch.div(input, value, out=None) 逐元素除以标量值\n",
    "* torch.exp  \n",
    "* torch.log \n",
    "* torch.pow    \n",
    "  torch.pow(input, exponent, out=None) 幂值\n",
    "* torch.sqrt 平方根"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **其他函数**\n",
    "\n",
    "* torch.sigmod \n",
    "* torch.clamp   \n",
    "  torch.clamp(input, min, max, out=None)  夹紧到区间 [min,max]\n",
    "  \n",
    "  \n",
    "* torch.abs\n",
    "* torch.neg 按元素取负 \n",
    "* torch.sign 正负 \n",
    "\n",
    "\n",
    "* torch.ceil  向上取整\n",
    "* torch.floor 向下取整\n",
    "\n",
    "\n",
    "* torch.frac 取分数部分\n",
    "* torch.trunc 截断值 取整\n",
    "\n",
    "\n",
    "* torch.fmod 除法余数\n",
    "\n",
    "* torch.round 舍入到最近的整数\n",
    "\n",
    "\n",
    "* torch.reciprocal 倒数\n",
    "* torch.rsqrt 平方根倒数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3271,  0.4525,  0.0740],\n",
      "        [ 0.1732,  0.2933,  1.9344]])\n",
      "tensor([[-0.3271,  0.4525,  0.0740],\n",
      "        [ 0.1732,  0.2933,  0.9344]])\n",
      "tensor([[-1.,  0.,  0.],\n",
      "        [ 0.,  0.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "print(a)\n",
    "print(torch.frac(a))\n",
    "print(torch.trunc(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7535,  2.2101, 13.5068],\n",
       "         [ 5.7721,  3.4093,  0.5170]]),\n",
       " tensor([[-0.7535,  2.2101, 13.5068],\n",
       "         [ 5.7721,  3.4093,  0.5170]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/a,a.reciprocal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction Ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.mean\n",
    "* torch.median\n",
    "* torch.mode 众数\n",
    "* torch.prod 积\n",
    "* torch.std\n",
    "* torch.sum\n",
    "* torch.var\n",
    "   \n",
    "* torch.cumprod 累积\n",
    "* torch.cumsum 累加\n",
    "* torch.norm \n",
    "    torch.norm(input, p=2) p范数\n",
    "* torch.dist \n",
    "    torch.dist(input, other, p=2, out=None)  (input- other) 的范数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Ops 比较操作 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.eq -->Tensor  逐元素相等\n",
    "* torch.equal  相同的形状和元素值\n",
    "* torch.ge     >=\n",
    "* torch.gt     >\n",
    "* torch.le     <=\n",
    "* torch.lt     <\n",
    "* torch.ne     !=\n",
    "* torch.max \n",
    "* torch.min \n",
    "* torch.sort   \n",
    "   torch.sort(input, dim=None, descending=False, out=None) -> (Tensor, LongTensor)  \n",
    "    对输入张量input沿着指定维按升序排序。如果不给定dim，则默认为输入的最后一维。  \n",
    "    如果指定参数descending为True，则按降序排序\n",
    "    \n",
    "* torch.topk   \n",
    "    torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -> (Tensor, LongTensor)\n",
    "    沿给定dim维度返回输入张量input中 k 个最大值。 如果不指定dim，则默认为input的最后一维。 \n",
    "    如果为largest为 False ，则返回最小的 k 个值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(torch.Tensor([1,3]),torch.Tensor([1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(torch.Tensor([1,2]),torch.Tensor([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* torch.diag\n",
    "         torch.diag(input, diagonal=0, out=None) → Tensor\n",
    "         如果输入是一个向量(1D 张量)，则返回一个以input为对角线元素的2D方阵\n",
    "         如果输入是一个矩阵(2D 张量)，则返回一个包含input对角线元素的1D张量\n",
    "        diagonal = 0, 主对角线\n",
    "        diagonal > 0, 主对角线之上\n",
    "        diagonal < 0, 主对角线之下\n",
    "* torch.trace   输入2维矩阵对角线元素的和(迹)\n",
    "* torch.addbmm \n",
    "       torch.addbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor\n",
    "       res=(beta∗M)+(alpha∗sum(batch1i@batch2i,i=0,b))\n",
    "* torch.addmm\n",
    "       torch.addmm(beta=1, mat, alpha=1, mat1, mat2, out=None) → Tensor\n",
    "       out=(beta∗M)+(alpha∗mat1@mat2)\n",
    "* torch.addmv\n",
    "       torch.addmv(beta=1, tensor, alpha=1, mat, vec, out=None) → Tensor\n",
    "         out=(beta∗tensor)+(alpha∗(mat@vec))\n",
    "* torch.bmm\n",
    "        torch.bmm(batch1, batch2, out=None) → Tensor 批矩阵乘操作\n",
    "        batch1: b×n×m    batch2 : b×m×p  out: b×n×p\n",
    "                \n",
    "* torch.dot  1-D 向量 点乘\n",
    "* torch.eig  特征值和特征向量\n",
    "* torch.ger \n",
    "        torch.ger(vec1, vec2, out=None) → Tensor\n",
    "        计算两向量vec1,vec2的张量积。如果vec1的长度为n,vec2长度为m，则输出out应为形如n x m的矩阵\n",
    "* torch.mm 矩阵相乘\n",
    "* torch.mv 对矩阵mat和向量vec进行相乘\n",
    "* torch.svd   A 进行奇异值分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
