{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.cat\n",
    "torch.cat(inputs,dimens=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,4)\n",
    "torch.cat((x,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.stack\n",
    "torch.stack(sequence, dim=0)   \n",
    "在维度上连接（concatenate）若干个张量。(这些张量形状相同）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4]) torch.Size([2, 3, 4]) torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(0,8).view(2,4)\n",
    "b = torch.arange(10,18).view(2,4)\n",
    "c = torch.arange(100,108).view(2,4)\n",
    "x =torch.stack((a,b,c),dim=0)\n",
    "y = torch.stack((a,b,b),dim=1)\n",
    "z = torch.stack((a,b,b),dim=2)\n",
    "print(x.size(),y.size(),z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.chunk\n",
    "torch.chunk(tensor, chunks, dim=0) chunks 分块个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0631, 0.2014, 0.4618, 0.0386, 0.7897, 0.4091, 0.0462, 0.0468],\n",
      "        [0.1436, 0.9544, 0.0616, 0.6193, 0.8887, 0.9349, 0.9854, 0.4089],\n",
      "        [0.8058, 0.4348, 0.0617, 0.0345, 0.3419, 0.8109, 0.1779, 0.0532]]), tensor([[0.3001, 0.1326, 0.4118, 0.3709, 0.3354, 0.0811, 0.3897, 0.4254],\n",
      "        [0.1158, 0.3227, 0.7693, 0.8539, 0.0362, 0.6780, 0.2802, 0.1158],\n",
      "        [0.5312, 0.5786, 0.5035, 0.8330, 0.2437, 0.6671, 0.9198, 0.5265]]))\n"
     ]
    }
   ],
   "source": [
    "a= torch.rand(6,8)\n",
    "print(torch.chunk(a,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.0631, 0.2014, 0.4618, 0.0386, 0.7897, 0.4091, 0.0462, 0.0468]]), tensor([[0.1436, 0.9544, 0.0616, 0.6193, 0.8887, 0.9349, 0.9854, 0.4089]]), tensor([[0.8058, 0.4348, 0.0617, 0.0345, 0.3419, 0.8109, 0.1779, 0.0532]]), tensor([[0.3001, 0.1326, 0.4118, 0.3709, 0.3354, 0.0811, 0.3897, 0.4254]]), tensor([[0.1158, 0.3227, 0.7693, 0.8539, 0.0362, 0.6780, 0.2802, 0.1158]]), tensor([[0.5312, 0.5786, 0.5035, 0.8330, 0.2437, 0.6671, 0.9198, 0.5265]]))\n"
     ]
    }
   ],
   "source": [
    "print(torch.chunk(a,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.split\n",
    "torch.split(tensor, split_size, dim=0)  #split_size 最后一块可能小于split_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0631, 0.2014, 0.4618, 0.0386, 0.7897, 0.4091, 0.0462, 0.0468],\n",
       "         [0.1436, 0.9544, 0.0616, 0.6193, 0.8887, 0.9349, 0.9854, 0.4089],\n",
       "         [0.8058, 0.4348, 0.0617, 0.0345, 0.3419, 0.8109, 0.1779, 0.0532],\n",
       "         [0.3001, 0.1326, 0.4118, 0.3709, 0.3354, 0.0811, 0.3897, 0.4254]]),\n",
       " tensor([[0.1158, 0.3227, 0.7693, 0.8539, 0.0362, 0.6780, 0.2802, 0.1158],\n",
       "         [0.5312, 0.5786, 0.5035, 0.8330, 0.2437, 0.6671, 0.9198, 0.5265]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a,4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.gather\n",
    "torch.gather(input, dim, index, out=None) → Tensor   \n",
    "沿给定轴dim，将输入索引张量index指定位置的值进行聚合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [4, 3]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t= torch.tensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "torch.gather(t,1,torch.LongTensor([[0,0],[1,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(t,0,torch.LongTensor([[0,0],[1,0]]))\n",
    "# 理解 dim =0  从左往右 分成列，在从上向下去取index 位置  返回结果的size与index的维度相同\n",
    "# 理解 dim =1  从上往下 分成行，在从左向右取index 位置  返回结果的size与index的维度相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6],\n",
       "        [1, 4]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2= torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(t2)\n",
    "torch.gather(t2,0,torch.LongTensor([[1,2]]))\n",
    "torch.gather(t2,0,torch.LongTensor([[1,2],[0,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.index_select\n",
    "torch.index_select(input, dim, index, out=None) → Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [6]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(t2,1,torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(t2,0,torch.LongTensor([1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  torch.mask_select\n",
    "torch.masked_select(input, mask, out=None) → Tensor    \n",
    "输入张量对应位置的元素是否保留，既然是一一对应的关系，这就需要传入 mask 中的布尔张量和传入 input 中的输入张量形状要相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8483,  0.4649, -0.2564, -0.1502],\n",
      "        [-0.7617, -0.3410,  0.5247,  2.0766],\n",
      "        [ 0.9188, -0.0397, -0.7750,  1.2267]])\n",
      "tensor([[ True,  True, False, False],\n",
      "        [False, False,  True,  True],\n",
      "        [ True, False, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,4)\n",
    "mask = x.ge(0)\n",
    "print(x)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8483, 0.4649, 0.5247, 2.0766, 0.9188, 1.2267])\n"
     ]
    }
   ],
   "source": [
    "print(torch.masked_select(x,mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 换位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.squeeze torch.unsqueeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([3, 1, 4])\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "y = torch.unsqueeze(x,1)\n",
    "print(y.size())\n",
    "z = x.squeeze()\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.t torch.transpose \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(a).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(a,1,0).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[0, 4],\n",
      "        [1, 5],\n",
      "        [2, 6],\n",
      "        [3, 7]])\n",
      "torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(a.size())\n",
    "print(a.permute(1,0))\n",
    "x = torch.randn(2,3,4)\n",
    "print(x.permute(1,2,0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248.906px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
